{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "YqEt2BYFR_kO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "slZnjqR_Ref1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the dataset"
      ],
      "metadata": {
        "id": "9ObDo8onSDxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root = './data',train = True,download = True, transform = transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size = 4,shuffle = True, num_workers = 2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root = './data',train = False,download = True,transform = transform)\n",
        "testloader = torch.utils.data.DataLoader(testset,batch_size = 4, shuffle = False, num_workers = 2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFibV914RztK",
        "outputId": "1f153003-8555-4baa-8fed-918dee08ab06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 30.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN Architecture"
      ],
      "metadata": {
        "id": "ZsXTS75NYiS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module) :\n",
        "  def __init__(self):\n",
        "    super(Network,self).__init__()\n",
        "\n",
        "    self.Conv1 = nn.Conv2d(3,32,kernel_size = 3,padding = 1)\n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "    self.Conv2 = nn.Conv2d(32,64,kernel_size = 3,padding = 1)\n",
        "    self.bn2 = nn.BatchNorm2d(64)\n",
        "    self.Conv3 = nn.Conv2d(64,128,kernel_size = 3, padding = 1)\n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
        "\n",
        "    self.fc = nn.Linear(128,10)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "  def forward(self,x):\n",
        "      x = self.pool(F.relu(self.bn1(self.Conv1(x))))\n",
        "      x = self.pool(F.relu(self.bn2(self.Conv2(x))))\n",
        "      x = self.pool(F.relu(self.bn3(self.Conv3(x))))\n",
        "      x = self.gap(x)\n",
        "      x = torch.flatten(x,1)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc(x)\n",
        "      return x\n",
        "\n",
        "net = Network()"
      ],
      "metadata": {
        "id": "q3OqOUULUYcv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "cn2uFSRwet73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(net.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "xKVxEbSnbX8p"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Network"
      ],
      "metadata": {
        "id": "XQVhBCQ1fgmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.to(device)\n",
        "for epoch in range(5):\n",
        "  net.train()\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for i,data in enumerate(trainloader,0):\n",
        "    inputs,labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999:\n",
        "      print(f\"[Epoch {epoch + 1}, Batch {i + 1}] Loss: {running_loss / 2000:.3f}\")\n",
        "      running_loss = 0.0\n",
        "print(\"Training Finished\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TQx1E0KfjcG",
        "outputId": "10d58147-bdaa-48db-fe5f-76c4c2b98b05"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 2000] Loss: 1.544\n",
            "[Epoch 1, Batch 4000] Loss: 1.537\n",
            "[Epoch 1, Batch 6000] Loss: 1.521\n",
            "[Epoch 1, Batch 8000] Loss: 1.528\n",
            "[Epoch 1, Batch 10000] Loss: 1.501\n",
            "[Epoch 1, Batch 12000] Loss: 1.500\n",
            "[Epoch 2, Batch 2000] Loss: 1.469\n",
            "[Epoch 2, Batch 4000] Loss: 1.469\n",
            "[Epoch 2, Batch 6000] Loss: 1.453\n",
            "[Epoch 2, Batch 8000] Loss: 1.483\n",
            "[Epoch 2, Batch 10000] Loss: 1.476\n",
            "[Epoch 2, Batch 12000] Loss: 1.431\n",
            "[Epoch 3, Batch 2000] Loss: 1.436\n",
            "[Epoch 3, Batch 4000] Loss: 1.429\n",
            "[Epoch 3, Batch 6000] Loss: 1.424\n",
            "[Epoch 3, Batch 8000] Loss: 1.415\n",
            "[Epoch 3, Batch 10000] Loss: 1.432\n",
            "[Epoch 3, Batch 12000] Loss: 1.419\n",
            "[Epoch 4, Batch 2000] Loss: 1.381\n",
            "[Epoch 4, Batch 4000] Loss: 1.383\n",
            "[Epoch 4, Batch 6000] Loss: 1.386\n",
            "[Epoch 4, Batch 8000] Loss: 1.404\n",
            "[Epoch 4, Batch 10000] Loss: 1.387\n",
            "[Epoch 4, Batch 12000] Loss: 1.363\n",
            "[Epoch 5, Batch 2000] Loss: 1.367\n",
            "[Epoch 5, Batch 4000] Loss: 1.373\n",
            "[Epoch 5, Batch 6000] Loss: 1.358\n",
            "[Epoch 5, Batch 8000] Loss: 1.354\n",
            "[Epoch 5, Batch 10000] Loss: 1.354\n",
            "[Epoch 5, Batch 12000] Loss: 1.347\n",
            "Training Finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the Network"
      ],
      "metadata": {
        "id": "p42kl8c9kNmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    inputs,labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = net(inputs)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkQGXvTjiiKh",
        "outputId": "b2d8ff30-ba9c-4bf4-b9e0-383486e16138"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 61.80 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optical Extension"
      ],
      "metadata": {
        "id": "KJTF5Rsw_m4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "net = models.resnet18(pretrained = True)\n",
        "num_ftrs = net.fc.in_features\n",
        "net.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "net.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(net.parameters(), lr=0.0001)\n",
        "\n",
        "for epoch in range(5):\n",
        "  net.train()\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for i,data in enumerate(trainloader,0):\n",
        "    inputs,labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999:\n",
        "      print(f\"[Epoch {epoch + 1}, Batch {i + 1}] Loss: {running_loss / 2000:.3f}\")\n",
        "      running_loss = 0.0\n",
        "print(\"Training Finished\")\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    inputs,labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = net(inputs)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS9uuaRGnB5M",
        "outputId": "a4067710-58be-4533-a016-089e172269ef"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 191MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 2000] Loss: 1.858\n",
            "[Epoch 1, Batch 4000] Loss: 1.692\n",
            "[Epoch 1, Batch 6000] Loss: 1.601\n",
            "[Epoch 1, Batch 8000] Loss: 1.509\n",
            "[Epoch 1, Batch 10000] Loss: 1.430\n",
            "[Epoch 1, Batch 12000] Loss: 1.363\n",
            "[Epoch 2, Batch 2000] Loss: 1.282\n",
            "[Epoch 2, Batch 4000] Loss: 1.240\n",
            "[Epoch 2, Batch 6000] Loss: 1.224\n",
            "[Epoch 2, Batch 8000] Loss: 1.168\n",
            "[Epoch 2, Batch 10000] Loss: 1.143\n",
            "[Epoch 2, Batch 12000] Loss: 1.108\n",
            "[Epoch 3, Batch 2000] Loss: 1.028\n",
            "[Epoch 3, Batch 4000] Loss: 1.019\n",
            "[Epoch 3, Batch 6000] Loss: 0.979\n",
            "[Epoch 3, Batch 8000] Loss: 0.995\n",
            "[Epoch 3, Batch 10000] Loss: 0.944\n",
            "[Epoch 3, Batch 12000] Loss: 0.948\n",
            "[Epoch 4, Batch 2000] Loss: 0.856\n",
            "[Epoch 4, Batch 4000] Loss: 0.880\n",
            "[Epoch 4, Batch 6000] Loss: 0.859\n",
            "[Epoch 4, Batch 8000] Loss: 0.845\n",
            "[Epoch 4, Batch 10000] Loss: 0.844\n",
            "[Epoch 4, Batch 12000] Loss: 0.840\n",
            "[Epoch 5, Batch 2000] Loss: 0.778\n",
            "[Epoch 5, Batch 4000] Loss: 0.757\n",
            "[Epoch 5, Batch 6000] Loss: 0.750\n",
            "[Epoch 5, Batch 8000] Loss: 0.734\n",
            "[Epoch 5, Batch 10000] Loss: 0.772\n",
            "[Epoch 5, Batch 12000] Loss: 0.752\n",
            "Training Finished\n",
            "Accuracy of the network on the 10000 test images: 71.57 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jf22B0RF_3ae"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}