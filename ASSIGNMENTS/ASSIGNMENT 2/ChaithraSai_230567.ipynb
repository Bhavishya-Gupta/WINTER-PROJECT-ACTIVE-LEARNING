{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define dataset transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# Download and load the CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
        "\n",
        "classes = trainset.classes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmx-IAq5QmAf",
        "outputId": "21bf3c5c-52ba-4e4d-e11e-09d11e100ff3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN()\n"
      ],
      "metadata": {
        "id": "sf51DMIpRBdi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # Print every 100 mini-batches\n",
        "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oAWKwiGRFDr",
        "outputId": "6f4117f8-88c7-4649-9df7-00c4288843f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 100] loss: 1.907\n",
            "[1, 200] loss: 1.554\n",
            "[1, 300] loss: 1.482\n",
            "[1, 400] loss: 1.390\n",
            "[1, 500] loss: 1.318\n",
            "[1, 600] loss: 1.291\n",
            "[1, 700] loss: 1.221\n",
            "[1, 800] loss: 1.214\n",
            "[1, 900] loss: 1.141\n",
            "[1, 1000] loss: 1.107\n",
            "[1, 1100] loss: 1.111\n",
            "[1, 1200] loss: 1.081\n",
            "[1, 1300] loss: 1.087\n",
            "[1, 1400] loss: 1.039\n",
            "[1, 1500] loss: 0.998\n",
            "[2, 100] loss: 0.953\n",
            "[2, 200] loss: 0.936\n",
            "[2, 300] loss: 0.955\n",
            "[2, 400] loss: 0.902\n",
            "[2, 500] loss: 0.908\n",
            "[2, 600] loss: 0.919\n",
            "[2, 700] loss: 0.882\n",
            "[2, 800] loss: 0.886\n",
            "[2, 900] loss: 0.890\n",
            "[2, 1000] loss: 0.851\n",
            "[2, 1100] loss: 0.874\n",
            "[2, 1200] loss: 0.818\n",
            "[2, 1300] loss: 0.844\n",
            "[2, 1400] loss: 0.857\n",
            "[2, 1500] loss: 0.875\n",
            "[3, 100] loss: 0.726\n",
            "[3, 200] loss: 0.737\n",
            "[3, 300] loss: 0.744\n",
            "[3, 400] loss: 0.723\n",
            "[3, 500] loss: 0.730\n",
            "[3, 600] loss: 0.721\n",
            "[3, 700] loss: 0.738\n",
            "[3, 800] loss: 0.768\n",
            "[3, 900] loss: 0.701\n",
            "[3, 1000] loss: 0.729\n",
            "[3, 1100] loss: 0.754\n",
            "[3, 1200] loss: 0.743\n",
            "[3, 1300] loss: 0.747\n",
            "[3, 1400] loss: 0.714\n",
            "[3, 1500] loss: 0.732\n",
            "[4, 100] loss: 0.599\n",
            "[4, 200] loss: 0.605\n",
            "[4, 300] loss: 0.618\n",
            "[4, 400] loss: 0.594\n",
            "[4, 500] loss: 0.624\n",
            "[4, 600] loss: 0.619\n",
            "[4, 700] loss: 0.602\n",
            "[4, 800] loss: 0.622\n",
            "[4, 900] loss: 0.605\n",
            "[4, 1000] loss: 0.628\n",
            "[4, 1100] loss: 0.615\n",
            "[4, 1200] loss: 0.620\n",
            "[4, 1300] loss: 0.620\n",
            "[4, 1400] loss: 0.610\n",
            "[4, 1500] loss: 0.635\n",
            "[5, 100] loss: 0.486\n",
            "[5, 200] loss: 0.499\n",
            "[5, 300] loss: 0.474\n",
            "[5, 400] loss: 0.494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "tPfDE0RBT1hQ",
        "outputId": "04967a1b-37db-4771-a36b-4734bb604fb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 72.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning a pretrained model\n",
        "from torchvision import models\n",
        "\n",
        "pretrained_model = models.resnet18(pretrained=True)\n",
        "pretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, 10)\n",
        "\n",
        "# Freeze layers except the final fully connected layer\n",
        "for param in pretrained_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in pretrained_model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Define optimizer and criterion for pretrained model\n",
        "optimizer = optim.Adam(pretrained_model.fc.parameters(), lr=0.001)\n",
        "\n",
        "# Similar training loop can be implemented as before for fine-tuning\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "jArX-NbwT_zZ",
        "outputId": "00ce1da2-5447-4fee-f380-a21641af462b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 180MB/s]\n"
          ]
        }
      ]
    }
  ]
}