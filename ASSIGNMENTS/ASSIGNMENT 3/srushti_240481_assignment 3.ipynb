{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be854a9-f5b3-46d4-a4a3-36874a05161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cu118\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\n",
    "from scipy.stats import entropy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 1. Data Preparation ---\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "full_trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                             download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                            download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Split into labeled and unlabeled datasets (example: 10% labeled)\n",
    "labeled_size = int(0.1 * len(full_trainset))\n",
    "unlabeled_size = len(full_trainset) - labeled_size\n",
    "labeled_dataset, unlabeled_dataset = torch.utils.data.random_split(full_trainset, [labeled_size, unlabeled_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 128\n",
    "labeled_loader = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# --- 2. Model Definition ---\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        #feature extractor\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            self.conv1,\n",
    "            nn.ReLU(),\n",
    "            self.pool,\n",
    "            self.conv2,\n",
    "            nn.ReLU(),\n",
    "            self.pool,\n",
    "            self.conv3,\n",
    "            nn.ReLU(),\n",
    "            self.pool\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        x = features.view(-1, 64 * 3 * 3)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x, features\n",
    "\n",
    "# --- 3. Query Strategies ---\n",
    "def least_confidence(model, unlabeled_loader, num_samples_to_query, device):\n",
    "    \"\"\"Selects samples with least confidence.\"\"\"\n",
    "    model.eval()\n",
    "    confidences = []\n",
    "    indices = []\n",
    "    for i, (images, _) in enumerate(unlabeled_loader):\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs, _ = model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        max_probabilities, _ = torch.max(probabilities, dim=1)\n",
    "        confidences.extend(max_probabilities.cpu().tolist())\n",
    "        indices.extend(range(i * unlabeled_loader.batch_size, (i + 1) * unlabeled_loader.batch_size))\n",
    "\n",
    "    sorted_indices = np.argsort(confidences)\n",
    "    return [indices[i] for i in sorted_indices[:num_samples_to_query]]\n",
    "\n",
    "def prediction_entropy(model, unlabeled_loader, num_samples_to_query, device):\n",
    "    \"\"\"Selects samples with highest prediction entropy.\"\"\"\n",
    "    model.eval()\n",
    "    entropies = []\n",
    "    indices = []\n",
    "    for i, (images, _) in enumerate(unlabeled_loader):\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs, _ = model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        batch_entropies = [entropy(p.cpu().numpy()) for p in probabilities]\n",
    "        entropies.extend(batch_entropies)\n",
    "        indices.extend(range(i * unlabeled_loader.batch_size, (i + 1) * unlabeled_loader.batch_size))\n",
    "    sorted_indices = np.argsort(entropies)[::-1]\n",
    "    return [indices[i] for i in sorted_indices[:num_samples_to_query]]\n",
    "\n",
    "def margin_sampling(model, unlabeled_loader, num_samples_to_query, device):\n",
    "    \"\"\"Selects samples with smallest margin between top two probabilities.\"\"\"\n",
    "    model.eval()\n",
    "    margins = []\n",
    "    indices = []\n",
    "    for i, (images, _) in enumerate(unlabeled_loader):\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs, _ = model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        sorted_probs, _ = torch.sort(probabilities, dim=1, descending=True)\n",
    "        batch_margins = sorted_probs[:, 0] - sorted_probs[:, 1]\n",
    "        margins.extend(batch_margins.cpu().tolist())\n",
    "        indices.extend(range(i * unlabeled_loader.batch_size, (i + 1) * unlabeled_loader.batch_size))\n",
    "\n",
    "    sorted_indices = np.argsort(margins)\n",
    "    return [indices[i] for i in sorted_indices[:num_samples_to_query]]\n",
    "\n",
    "def cosine_similarity_diversity(model, unlabeled_loader, num_samples_to_query, device):\n",
    "    \"\"\"Selects diverse samples based on cosine similarity of their features.\"\"\"\n",
    "    model.eval()\n",
    "    features = []\n",
    "    indices = []\n",
    "    for i, (images, _) in enumerate(unlabeled_loader):\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, batch_features = model(images)\n",
    "        batch_features = batch_features.view(batch_features.size(0), -1)  # Flatten features\n",
    "        features.extend(batch_features.cpu().numpy())\n",
    "        indices.extend(range(i * unlabeled_loader.batch_size, (i + 1) * unlabeled_loader.batch_size))\n",
    "\n",
    "    similarity_matrix = cosine_similarity(features)\n",
    "    np.fill_diagonal(similarity_matrix, 1)\n",
    "    diversity_scores = np.sum(similarity_matrix, axis=1) / (similarity_matrix.shape[0] - 1)\n",
    "\n",
    "    sorted_indices = np.argsort(diversity_scores)\n",
    "    return [indices[i] for i in sorted_indices[:num_samples_to_query]]\n",
    "\n",
    "def l2_norm_diversity(model, unlabeled_loader, num_samples_to_query, device):\n",
    "    \"\"\"Selects diverse samples based on L2 norm (Euclidean distance) of their features.\"\"\"\n",
    "    model.eval()\n",
    "    features = []\n",
    "    indices = []\n",
    "    for i, (images, _) in enumerate(unlabeled_loader):\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, batch_features = model(images)\n",
    "        batch_features = batch_features.view(batch_features.size(0), -1)  # Flatten features\n",
    "        features.extend(batch_features.cpu().numpy())\n",
    "        indices.extend(range(i * unlabeled_loader.batch_size, (i + 1) * unlabeled_loader.batch_size))\n",
    "\n",
    "    distances = np.sqrt(((np.array(features)[:, np.newaxis, :] - np.array(features)[np.newaxis, :, :]) ** 2).sum(axis=2))\n",
    "    diversity_scores = np.sum(distances, axis=1)\n",
    "\n",
    "    sorted_indices = np.argsort(diversity_scores)[::-1]\n",
    "    return [indices[i] for i in sorted_indices[:num_samples_to_query]]\n",
    "\n",
    "def kl_divergence_diversity(model, labeled_loader, unlabeled_loader, num_samples_to_query, device):\n",
    "    \"\"\"Selects diverse samples based on KL divergence of their predicted probabilities.\"\"\"\n",
    "    model.eval()\n",
    "    labeled_probs = []\n",
    "    for images, _ in labeled_loader:\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs, _ = model(images)\n",
    "        probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "        labeled_probs.extend(probs)\n",
    "\n",
    "    labeled_distribution = np.mean(labeled_probs, axis=0)\n",
    "\n",
    "    unlabeled_probs = []\n",
    "    indices = []\n",
    "    for i, (images, _) in enumerate(unlabeled_loader):\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs, _ = model(images)\n",
    "        probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "        unlabeled_probs.extend(probs)\n",
    "        indices.extend(range(i * unlabeled_loader.batch_size, (i + 1) * unlabeled_loader.batch_size))\n",
    "\n",
    "    kl_divergences = [entropy(p, labeled_distribution) for p in unlabeled_probs]\n",
    "    sorted_indices = np.argsort(kl_divergences)[::-1]\n",
    "    return [indices[i] for i in sorted_indices[:num_samples_to_query]]\n",
    "\n",
    "# --- 4. Training and Evaluation Functions ---\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5, device=device):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "def evaluate_model(model, testloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs, _ = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# --- 5. Active Learning Loop ---\n",
    "def active_learning(net, criterion, optimizer, labeled_dataset, unlabeled_dataset, testloader, device, num_iterations=5, num_samples_to_query=10, query_strategy=least_confidence, diversity_strategy = None):\n",
    "    # Trackers\n",
    "    active_learning_accuracies = []\n",
    "    baseline_accuracies = []\n",
    "    labeled_dataset_sizes = []\n",
    "\n",
    "    # Save initial model state for baseline training\n",
    "    initial_model_state = net.state_dict()\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        print(f\"Active learning iteration {i+1}/{num_iterations}...\")\n",
    "\n",
    "        # Create new dataloaders\n",
    "        batch_size = 128\n",
    "        labeled_loader = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True)\n",
    "        unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Query Strategy\n",
    "        query_indices = query_strategy(net, unlabeled_loader, num_samples_to_query, device)\n",
    "        if diversity_strategy is not None:\n",
    "          query_indices = diversity_strategy(net, labeled_loader, unlabeled_loader, num_samples_to_query, device)\n",
    "        queried_samples = Subset(unlabeled_dataset, query_indices)\n",
    "\n",
    "        # get the labels for the queried samples\n",
    "        new_labels = [unlabeled_dataset.dataset.targets[index] for index in queried_samples.indices]\n",
    "\n",
    "        # Create the new labeled dataset:\n",
    "        new_dataset = []\n",
    "        for index in queried_samples.indices:\n",
    "          image, label = unlabeled_dataset.dataset[index]\n",
    "          new_dataset.append((image,label))\n",
    "        labeled_dataset = ConcatDataset([labeled_dataset, new_dataset])\n",
    "\n",
    "        # Remove queried samples from the unlabeled dataset\n",
    "        unlabeled_indices = [idx for idx in range(len(unlabeled_dataset)) if idx not in query_indices]\n",
    "        unlabeled_dataset = Subset(unlabeled_dataset, unlabeled_indices)\n",
    "\n",
    "        # Create new data loaders\n",
    "        labeled_loader = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True)\n",
    "        unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=False)\n",
    "        # Retrain the model\n",
    "        train_model(net, labeled_loader, criterion, optimizer)\n",
    "\n",
    "        # Calculate active learning accuracy\n",
    "        active_learning_accuracy = evaluate_model(net, testloader, device)\n",
    "        print(f\"Active Learning Accuracy: {active_learning_accuracy}%\")\n",
    "        active_learning_accuracies.append(active_learning_accuracy)\n",
    "        labeled_dataset_sizes.append(len(labeled_dataset))\n",
    "\n",
    "        # Calculate Baseline accuracy\n",
    "        # Reset model to initial state for baseline training\n",
    "        net.load_state_dict(initial_model_state)\n",
    "        # Train baseline model on the current labeled dataset\n",
    "        train_model(net, labeled_loader, criterion, optimizer)\n",
    "\n",
    "        # Evaluate baseline model\n",
    "        baseline_accuracy = evaluate_model(net, testloader, device)\n",
    "        print(f\"Baseline Accuracy: {baseline_accuracy}%\")\n",
    "        baseline_accuracies.append(baseline_accuracy)\n",
    "    return labeled_dataset_sizes, active_learning_accuracies, baseline_accuracies\n",
    "\n",
    "# --- 6. Model, Criterion, Optimizer ---\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# --- 7. Run Active Learning ---\n",
    "num_iterations = 5\n",
    "num_samples_to_query = 100\n",
    "#Active Learning with least confidence query strategy\n",
    "labeled_dataset_sizes_lc, active_learning_accuracies_lc, baseline_accuracies_lc = active_learning(net, criterion, optimizer, labeled_dataset, unlabeled_dataset, testloader, device, num_iterations, num_samples_to_query, least_confidence)\n",
    "\n",
    "#Reset model and labeled/unlabeled datasets\n",
    "net = Net().to(device)\n",
    "labeled_dataset, unlabeled_dataset = torch.utils.data.random_split(full_trainset, [labeled_size, unlabeled_size])\n",
    "#Active learning with prediction entropy query strategy\n",
    "labeled_dataset_sizes_pe, active_learning_accuracies_pe, baseline_accuracies_pe = active_learning(net, criterion, optimizer, labeled_dataset, unlabeled_dataset, testloader, device, num_iterations, num_samples_to_query, prediction_entropy)\n",
    "\n",
    "#Reset model and labeled/unlabeled datasets\n",
    "net = Net().to(device)\n",
    "labeled_dataset, unlabeled_dataset = torch.utils.data.random_split(full_trainset, [labeled_size, unlabeled_size])\n",
    "#Active learning with margin sampling query strategy\n",
    "labeled_dataset_sizes_ms, active_learning_accuracies_ms, baseline_accuracies_ms = active_learning(net, criterion, optimizer, labeled_dataset, unlabeled_dataset, testloader, device, num_iterations, num_samples_to_query, margin_sampling)\n",
    "\n",
    "#Reset model and labeled/unlabeled datasets\n",
    "net = Net().to(device)\n",
    "labeled_dataset, unlabeled_dataset = torch.utils.data.random_split(full_trainset, [labeled_size, unlabeled_size])\n",
    "#Active learning with Cosine similarity diversity\n",
    "labeled_dataset_sizes_cs, active_learning_accuracies_cs, baseline_accuracies_cs = active_learning(net, criterion, optimizer, labeled_dataset, unlabeled_dataset, testloader, device, num_iterations, num_samples_to_query, least_confidence, cosine_similarity_diversity)\n",
    "\n",
    "#Reset model and labeled/unlabeled datasets\n",
    "net = Net().to(device)\n",
    "labeled_dataset, unlabeled_dataset = torch.utils.data.random_split(full_trainset, [labeled_size, unlabeled_size])\n",
    "#Active learning with L2 norm diversity\n",
    "labeled_dataset_sizes_l2, active_learning_accuracies_l2, baseline_accuracies_l2 = active_learning(net, criterion, optimizer, labeled_dataset, unlabeled_dataset, testloader, device, num_iterations, num_samples_to_query, least_confidence, l2_norm_diversity)\n",
    "\n",
    "#Reset model and labeled/unlabeled datasets\n",
    "net = Net().to(device)\n",
    "labeled_dataset, unlabeled_dataset = torch.utils.data.random_split(full_trainset, [labeled_size, unlabeled_size])\n",
    "#Active learning with KL divergence diversity\n",
    "labeled_dataset_sizes_kl, active_learning_accuracies_kl, baseline_accuracies_kl = active_learning(net, criterion, optimizer, labeled_dataset, unlabeled_dataset, testloader, device, num_iterations, num_samples_to_query, least_confidence, kl_divergence_diversity)\n",
    "\n",
    "# --- 8. Reporting and Analysis ---\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(labeled_dataset_sizes_lc, active_learning_accuracies_lc, label='Active Learning (Least Confidence)')\n",
    "plt.plot(labeled_dataset_sizes_lc, baseline_accuracies_lc, label='Baseline (Least Confidence)')\n",
    "plt.plot(labeled_dataset_sizes_pe, active_learning_accuracies_pe, label='Active Learning (Prediction Entropy)')\n",
    "plt.plot(labeled_dataset_sizes_pe, baseline_accuracies_pe, label='Baseline (Prediction Entropy)')\n",
    "plt.plot(labeled_dataset_sizes_ms, active_learning_accuracies_ms, label='Active Learning (Margin Sampling)')\n",
    "plt.plot(labeled_dataset_sizes_ms, baseline_accuracies_ms, label='Baseline (Margin Sampling)')\n",
    "plt.plot(labeled_dataset_sizes_cs, active_learning_accuracies_cs, label='Active Learning (Cosine Similarity)')\n",
    "plt.plot(labeled_dataset_sizes_cs, baseline_accuracies_cs, label='Baseline (Cosine Similarity)')\n",
    "plt.plot(labeled_dataset_sizes_l2, active_learning_accuracies_l2, label='Active Learning (L2 Norm)')\n",
    "plt.plot(labeled_dataset_sizes_l2, baseline_accuracies_l2, label='Baseline (L2 Norm)')\n",
    "plt.plot(labeled_dataset_sizes_kl, active_learning_accuracies_kl, label='Active Learning (KL Divergence)')\n",
    "plt.plot(labeled_dataset_sizes_kl, baseline_accuracies_kl, label='Baseline (KL Divergence)')\n",
    "plt.xlabel('Labeled Dataset Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Active Learning vs. Baseline Performance')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"  Custom CNN (Baseline Least Confidence): {baseline_accuracies_lc[-1]:.2f}%\")\n",
    "print(f\"  Active Learning-enhanced Model (Least Confidence): {active_learning_accuracies_lc[-1]:.2f}%\")\n",
    "print(f\"  Custom CNN (Baseline Prediction Entropy): {baseline_accuracies_pe[-1]:.2f}%\")\n",
    "print(f\"  Active Learning-enhanced Model (Prediction Entropy): {active_learning_accuracies_pe[-1]:.2f}%\")\n",
    "print(f\"  Custom CNN (Baseline Margin Sampling): {baseline_accuracies_ms[-1]:.2f}%\")\n",
    "print(f\"  Active Learning-enhanced Model (Margin Sampling): {active_learning_accuracies_ms[-1]:.2f}%\")\n",
    "print(f\"  Custom CNN (Baseline Cosine Similarity): {baseline_accuracies_cs[-1]:.2f}%\")\n",
    "print(f\"  Active Learning-enhanced Model (Cosine Similarity): {active_learning_accuracies_cs[-1]:.2f}%\")\n",
    "print(f\"  Custom CNN (Baseline L2 Norm): {baseline_accuracies_l2[-1]:.2f}%\")\n",
    "print(f\"  Active Learning-enhanced Model (L2 Norm): {active_learning_accuracies_l2[-1]:.2f}%\")\n",
    "print(f\"  Custom CNN (Baseline KL Divergence): {baseline_accuracies_kl[-1]:.2f}%\")\n",
    "print(f\"  Active Learning-enhanced Model (KL Divergence): {active_learning_accuracies_kl[-1]:.2f}%\")\n",
    "\n",
    "# Analyze Results (Example)\n",
    "print(\"\\nAnalysis:\")\n",
    "if active_learning_accuracies_lc[-1] > baseline_accuracies_lc[-1]:\n",
    "    print(\"  Active learning improved accuracy over the baseline with the least confidence strategy.\")\n",
    "else:\n",
    "    print(\"  Active learning did not improve accuracy over the baseline with the least confidence strategy in this run.\")\n",
    "\n",
    "if active_learning_accuracies_pe[-1] > baseline_accuracies_pe[-1]:\n",
    "    print(\"  Active learning improved accuracy over the baseline with the prediction entropy strategy.\")\n",
    "else:\n",
    "    print(\"  Active learning did not improve accuracy over the baseline with the prediction entropy strategy in this run.\")\n",
    "    \n",
    "if active_learning_accuracies_ms[-1] > baseline_accuracies_ms[-1]:\n",
    "    print(\"  Active learning improved accuracy over the baseline with the margin sampling strategy.\")\n",
    "else:\n",
    "    print(\"  Active learning did not improve accuracy over the baseline with the margin sampling strategy in this run.\")\n",
    "    \n",
    "if active_learning_accuracies_cs[-1] > baseline_accuracies_cs[-1]:\n",
    "    print(\"  Active learning improved accuracy over the baseline with the cosine similarity diversity strategy.\")\n",
    "else:\n",
    "    print(\"  Active learning did not improve accuracy over the baseline with the cosine similarity diversity strategy in this run.\")\n",
    "\n",
    "if active_learning_accuracies_l2[-1] > baseline_accuracies_l2[-1]:\n",
    "    print(\"  Active learning improved accuracy over the baseline with the L2 Norm diversity strategy.\")\n",
    "else:\n",
    "    print(\"  Active learning did not improve accuracy over the baseline with the L2 Norm diversity strategy in this run.\")\n",
    "    \n",
    "if active_learning_accuracies_kl[-1] > baseline_accuracies_kl[-1]:\n",
    "    print(\"  Active learning improved accuracy over the baseline with the KL Divergence diversity strategy.\")\n",
    "else:\n",
    "    print(\"  Active learning did not improve accuracy over the baseline with the KL Divergence diversity strategy in this run.\")\n",
    "\n",
    "#Highligh effective strategy\n",
    "best_active_learning_strategy = max(\n",
    "    {\n",
    "        \"Least Confidence\": active_learning_accuracies_lc[-1],\n",
    "        \"Prediction Entropy\": active_learning_accuracies_pe[-1],\n",
    "        \"Margin Sampling\": active_learning_accuracies_ms[-1],\n",
    "        \"Cosine Similarity\": active_learning_accuracies_cs[-1],\n",
    "        \"L2 Norm\": active_learning_accuracies_l2[-1],\n",
    "        \"KL Divergence\": active_learning_accuracies_kl[-1],\n",
    "    },\n",
    "    key=lambda k: max(\n",
    "        active_learning_accuracies_lc[-1] if k == \"Least Confidence\" else 0,\n",
    "        active_learning_accuracies_pe[-1] if k == \"Prediction Entropy\" else 0,\n",
    "        active_learning_accuracies_ms[-1] if k == \"Margin Sampling\" else 0,\n",
    "        active_learning_accuracies_cs[-1] if k == \"Cosine Similarity\" else 0,\n",
    "        active_learning_accuracies_l2[-1] if k == \"L2 Norm\" else 0,\n",
    "        active_learning_accuracies_kl[-1] if k == \"KL Divergence\" else 0,\n",
    "    ),\n",
    ")\n",
    "print(\"\\nMost Effective Strategy: \")\n",
    "print(f\"  In this run, the most effective strategy was: {best_active_learning_strategy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
