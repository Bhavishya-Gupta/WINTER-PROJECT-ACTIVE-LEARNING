{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b0aa17f-921f-400f-9a95-c22a6b4057c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967d4057-2aa2-4e69-8cd2-d18846cf6c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf86adf2-07fa-4eaa-9adf-728c8fbadf7a",
   "metadata": {},
   "source": [
    "### CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "246e4842-6af9-4e45-90ad-ea321f72aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(10, 25, 3, 1)\n",
    "        self.fc1 = nn.Linear(25*6*6, 120)\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(F.max_pool2d(x, 2, 2))\n",
    "        x = F.relu(F.max_pool2d(x, 2, 2))\n",
    "        x = x.view(-1, 25*6*6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9001e70-0cb9-475a-9085-c88a0a493484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNeuralNetwork(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 25, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=900, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutionalNeuralNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c86a443-e5f1-4689-800e-5ab48fad0f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7fb26-53ae-47c9-9352-86ef60052412",
   "metadata": {},
   "source": [
    "### Dataset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f6f580-473c-4e85-8a3f-a57e10aacd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f284a0f2-a2f8-43b4-875b-ae59163f7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root = 'cnn_data', train = True, download = True, transform = transform)\n",
    "test_data = datasets.MNIST(root = 'cnn_data', train = False, download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f195a9b-fd64-4424-b115-047810e6f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size = 10, shuffle = True)\n",
    "test_loader = DataLoader(test_data, batch_size = 10, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9988e441-e021-4040-bfff-fce607b8a1df",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "144b6f3a-7f80-4f8d-969b-60cd043006f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1     loss: 0.28211\n",
      "epoch: 2     loss: 0.16383\n",
      "epoch: 3     loss: 0.14707\n",
      "epoch: 4     loss: 0.14110\n",
      "epoch: 5     loss: 0.13508\n",
      "epoch: 6     loss: 0.13116\n",
      "epoch: 7     loss: 0.13404\n",
      "epoch: 8     loss: 0.12330\n",
      "epoch: 9     loss: 0.12296\n",
      "epoch: 10     loss: 0.12008\n"
     ]
    }
   ],
   "source": [
    "test_correct = 0\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for i, (X_train, y_train) in enumerate(train_loader):\n",
    "        y_prediction = model(X_train)\n",
    "        loss = loss_function(y_prediction, y_train)\n",
    "        total_loss += loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'epoch: {epoch + 1}     loss: {total_loss / len(train_loader) :.5f}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (X_test, y_test) in enumerate(test_loader):\n",
    "        y_value = model(X_test)\n",
    "        loss = loss_function(y_value, y_test)\n",
    "\n",
    "        test_correct += (torch.max(y_value, 1)[1] == y_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9752484-5d46-4396-857e-6279043d427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Custom CNN: 94.77%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for Custom CNN: {test_correct/len(test_data)*100 :.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f799ef3f-7b57-4771-81df-38e09187ddae",
   "metadata": {},
   "source": [
    "### Pretrained CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77cee2bc-11fe-4b7e-a204-27f1b511109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "pretrained_model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "pretrained_model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "pretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, 10)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(pretrained_model.parameters(), lr=0.0001)\n",
    "\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in pretrained_model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a782538-5c54-4ace-975b-2c7ff7aa3ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1     loss: 1.61612\n",
      "epoch: 2     loss: 1.35883\n",
      "epoch: 3     loss: 1.31816\n",
      "epoch: 4     loss: 1.30286\n",
      "epoch: 5     loss: 1.28714\n"
     ]
    }
   ],
   "source": [
    "test_correct = 0\n",
    "\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    for i, (X_train, y_train) in enumerate(train_loader):\n",
    "        y_prediction = pretrained_model(X_train)\n",
    "        loss = loss_function(y_prediction, y_train)\n",
    "        total_loss += loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'epoch: {epoch + 1}     loss: {total_loss / len(train_loader) :.5f}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (X_test, y_test) in enumerate(test_loader):\n",
    "        y_value = pretrained_model(X_test)\n",
    "        loss = loss_function(y_value, y_test)\n",
    "\n",
    "        test_correct += (torch.max(y_value, 1)[1] == y_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "760b7747-47f0-405c-b9b7-3c48c8d5b4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Pretrained Model: 59.04%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for Pretrained Model: {test_correct/len(test_data)*100 :.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4c311-23d2-4b70-8b18-7e59a476eb67",
   "metadata": {},
   "source": [
    "### Active Learning Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5379c10a-c8c9-46be-a46d-f0af9bf46122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNeuralNetwork(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 25, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=900, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutionalNeuralNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c32c668-4553-4124-8bea-e602200b930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e31679d5-fb63-4f06-9fe2-424a419df733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_least_confidence(outputs):\n",
    "    probabilities = F.softmax(outputs, dim=1)\n",
    "    least_confidence = 1 - probabilities.max(dim=1).values.detach().cpu().numpy()\n",
    "    return least_confidence\n",
    "\n",
    "def calculate_prediction_entropy(outputs):\n",
    "    probabilities = F.softmax(outputs, dim=1)\n",
    "    current_probs = probabilities.clone().detach()\n",
    "    current_probs[current_probs == 0] = 1e-10\n",
    "    prediction_entropy = -torch.sum(current_probs * torch.log(current_probs), dim=1).detach().cpu().numpy()\n",
    "    return prediction_entropy\n",
    "    \n",
    "def calculate_margin_sampling(outputs):\n",
    "    probabilities = F.softmax(outputs, dim=1)\n",
    "    sorted_probs, _ = probabilities.sort(dim=1, descending=True)\n",
    "    margin_sampling = (sorted_probs[:, 0] - sorted_probs[:, 1]).detach().cpu().numpy()\n",
    "    return margin_sampling\n",
    "\n",
    "def calculate_cosine_similarity(features, m=5):\n",
    "    feature_distances = pairwise_distances(features.cpu().detach().numpy(), metric='cosine')\n",
    "    cosine_similarity = 1 - feature_distances[:, 1:m+1].mean(axis=1)\n",
    "    return cosine_similarity\n",
    "\n",
    "def calculate_l2_norm(features, m=5):\n",
    "    l2_distances = pairwise_distances(features.cpu().detach().numpy(), metric='euclidean')\n",
    "    l2_norm = l2_distances[:, 1:m+1].mean(axis=1)\n",
    "    return l2_norm\n",
    "\n",
    "def calculate_kl_divergence(outputs, feature_distances, m=5):\n",
    "    kl_divergence = []\n",
    "    for i in range(len(outputs)):\n",
    "        current_sample_prob = F.softmax(outputs[i], dim=0)\n",
    "        neighbor_indices = feature_distances[i, 1:m+1].astype(int)\n",
    "        neighbors_prob = F.softmax(torch.mean(F.softmax(outputs[neighbor_indices], dim=1), dim=0), dim=0)\n",
    "        kl_divergence.append(F.kl_div(torch.log(current_sample_prob), neighbors_prob, reduction='batchmean').item())\n",
    "    return kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e0828be-9780-479c-b16e-2ece4fb986cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method: least confidence     iteration: 1     accuracy: 91.72%\n",
      "method: least confidence     iteration: 2     accuracy: 93.82%\n",
      "method: least confidence     iteration: 3     accuracy: 95.92%\n",
      "method: prediction entropy     iteration: 1     accuracy: 94.68%\n",
      "method: prediction entropy     iteration: 2     accuracy: 95.95%\n",
      "method: prediction entropy     iteration: 3     accuracy: 95.99%\n",
      "method: margin sampling     iteration: 1     accuracy: 96.06%\n",
      "method: margin sampling     iteration: 2     accuracy: 96.08%\n",
      "method: margin sampling     iteration: 3     accuracy: 96.15%\n",
      "method: cosine similarity     iteration: 1     accuracy: 96.16%\n",
      "method: cosine similarity     iteration: 2     accuracy: 93.87%\n",
      "method: cosine similarity     iteration: 3     accuracy: 95.37%\n",
      "method: l2 norm     iteration: 1     accuracy: 95.43%\n",
      "method: l2 norm     iteration: 2     accuracy: 93.66%\n",
      "method: l2 norm     iteration: 3     accuracy: 94.54%\n",
      "method: kl divergence     iteration: 1     accuracy: 94.79%\n",
      "method: kl divergence     iteration: 2     accuracy: 94.78%\n",
      "method: kl divergence     iteration: 3     accuracy: 94.82%\n"
     ]
    }
   ],
   "source": [
    "methods = ['least confidence', 'prediction entropy', 'margin sampling','cosine similarity', 'l2 norm', 'kl divergence']\n",
    "\n",
    "results = {method: [] for method in methods}\n",
    "\n",
    "for method in methods:\n",
    "    \n",
    "    labeled_set = list(range(1000))\n",
    "    unlabeled_set = list(range(1000, len(train_data)))\n",
    "\n",
    "    for iteration in range(3):\n",
    "        \n",
    "        labeled_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(train_data, labeled_set), batch_size=10, shuffle=True)\n",
    "        unlabeled_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(train_data, unlabeled_set), batch_size=10, shuffle=False)\n",
    "\n",
    "        for epochs in range(5):\n",
    "            for data in labeled_loader:\n",
    "                X_train, y_train = data\n",
    "                y_prediction = model(X_train)\n",
    "                loss = loss_function(y_prediction, y_train)\n",
    "        \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        test_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (X_test, y_test) in enumerate(test_loader):\n",
    "                y_value = model(X_test)\n",
    "                loss = loss_function(y_value, y_test)\n",
    "\n",
    "                test_correct += (torch.max(y_value, 1)[1] == y_test).sum()\n",
    "\n",
    "        print(f'method: {method}     iteration: {iteration + 1}     accuracy: {test_correct/len(test_data)*100 :.2f}%')\n",
    "        accuracy = test_correct / len(test_data) * 100\n",
    "        results[method].append(round(accuracy.item(), 2))\n",
    "\n",
    "        unlabeled_dataset = unlabeled_loader.dataset\n",
    "        unlabeled_subset = torch.utils.data.Subset(unlabeled_dataset, range(1000))\n",
    "        unlabeled_subset_loader = torch.utils.data.DataLoader(unlabeled_subset, batch_size=unlabeled_loader.batch_size, shuffle=False)\n",
    "        \n",
    "        outputs_list = []\n",
    "        features_list = []\n",
    "        for data in unlabeled_subset:\n",
    "            X, y = data\n",
    "            outputs = model(X)\n",
    "\n",
    "            features = model.extract_features(X)\n",
    "\n",
    "            outputs_list.append(outputs)\n",
    "            features_list.append(features)\n",
    "\n",
    "        outputs = torch.cat(outputs_list, dim=0)\n",
    "        features = torch.cat(features_list, dim=0)\n",
    "\n",
    "        if (method == 'least confidence'):\n",
    "            least_confidence = calculate_least_confidence(outputs)\n",
    "            scores = np.array(least_confidence)\n",
    "        elif (method == 'prediction entropy'):\n",
    "            prediction_entropy = calculate_prediction_entropy(outputs)\n",
    "            scores = -np.array(prediction_entropy)\n",
    "        elif (method == 'margin sampling'):\n",
    "            margin_sampling = calculate_margin_sampling(outputs)\n",
    "            scores = np.array(margin_sampling)\n",
    "        elif (method == 'cosine similarity'):\n",
    "            features_normalized = F.normalize(features, p=2, dim=1)\n",
    "            cosine_similarity = calculate_cosine_similarity(features_normalized)\n",
    "            scores = -np.array(cosine_similarity)\n",
    "        elif (method == 'l2 norm'):\n",
    "            features_normalized = F.normalize(features, p=2, dim=1)\n",
    "            l2_norm = calculate_l2_norm(features_normalized)\n",
    "            scores = -np.array(l2_norm)\n",
    "        elif (method == 'kl divergence'):\n",
    "            feature_distances = pairwise_distances(features.cpu().detach().numpy(), metric='cosine')\n",
    "            scores = calculate_kl_divergence(outputs, feature_distances)\n",
    "\n",
    "        top_indices = np.argsort(scores)[-200:]\n",
    "        new_samples = np.array(unlabeled_set)[top_indices].tolist()\n",
    "\n",
    "        labeled_set.extend(new_samples)\n",
    "        unlabeled_set = list(set(unlabeled_set) - set(new_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba16e25b-e273-4a8c-8df3-31a9dac32744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Iteration 1</th>\n",
       "      <th>Iteration 2</th>\n",
       "      <th>Iteration 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>least confidence</td>\n",
       "      <td>91.72</td>\n",
       "      <td>93.82</td>\n",
       "      <td>95.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prediction entropy</td>\n",
       "      <td>94.68</td>\n",
       "      <td>95.95</td>\n",
       "      <td>95.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>margin sampling</td>\n",
       "      <td>96.06</td>\n",
       "      <td>96.08</td>\n",
       "      <td>96.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cosine similarity</td>\n",
       "      <td>96.16</td>\n",
       "      <td>93.87</td>\n",
       "      <td>95.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l2 norm</td>\n",
       "      <td>95.43</td>\n",
       "      <td>93.66</td>\n",
       "      <td>94.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kl divergence</td>\n",
       "      <td>94.79</td>\n",
       "      <td>94.78</td>\n",
       "      <td>94.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Method  Iteration 1  Iteration 2  Iteration 3\n",
       "0    least confidence        91.72        93.82        95.92\n",
       "1  prediction entropy        94.68        95.95        95.99\n",
       "2     margin sampling        96.06        96.08        96.15\n",
       "3   cosine similarity        96.16        93.87        95.37\n",
       "4             l2 norm        95.43        93.66        94.54\n",
       "5       kl divergence        94.79        94.78        94.82"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"Method\": methods}\n",
    "for iteration in range(3):\n",
    "    data[f'Iteration {iteration + 1}'] = [results[method][iteration] for method in methods]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
